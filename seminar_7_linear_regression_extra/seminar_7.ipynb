{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача регрессии на реальных данных\n",
    "Рассмотрим датасет с ценами на жильё в Москве за 2011-2015 год, данные предоставлены [Сбербанком](https://www.kaggle.com/c/sberbank-russian-housing-market/data), спасибо им за это.\n",
    "\n",
    "А ещё:\n",
    "- научимся работать с категориальными (номинальными) признаками\n",
    "- поймём, почему важно нормализовать данные до того, как отправлять их считаться в модель\n",
    "- посмотрим на альтернативы sklearn'овской LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На том же сайте есть [пример](https://www.kaggle.com/captcalculator/a-very-extensive-sberbank-exploratory-analysis) хорошего первичного анализа. Откроем таблицу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('sberbank_moscow.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, признаков достаточно много (292), так что излюбленный метод `.info()` особо не поможет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на количество пропусков по столбцам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, про некоторые признаки данных не очень много, так что выберем колонки, смысл которых мы заведомо будем понимать. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'price_doc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_feature_columns = [\n",
    "    'sub_area',\n",
    "    'ecology',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[nominal_feature_columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_feature_columns = [\n",
    "    'full_sq',\n",
    "    'floor',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[internal_feature_columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_feature_columns = [\n",
    "    'children_preschool',\n",
    "    'children_school',\n",
    "    'school_education_centers_top_20_raion',\n",
    "    'university_top_20_raion',\n",
    "    'additional_education_km',\n",
    "    'university_km',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[school_feature_columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infrastructure_feature_columns = [\n",
    "    'nuclear_reactor_km',\n",
    "    'power_transmission_line_km',\n",
    "    'public_transport_station_km',\n",
    "    'public_transport_station_min_walk',\n",
    "    'mkad_km',\n",
    "    'kremlin_km',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[infrastructure_feature_columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрели на колонки и пропуски в них, теперь объединим всё в один список и будем использовать в качестве признаков только перечисленные столбцы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = nominal_feature_columns + internal_feature_columns + school_feature_columns + infrastructure_feature_columns + [target_column]\n",
    "len(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраните таблицу только с перечисленными колонками и удалите из неё все строки с пропусками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка мультиколлинеарности\n",
    "Посчитайте коэффициенты корреляции между колонками таблицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feature_columns = internal_feature_columns + school_feature_columns + infrastructure_feature_columns + [target_column]\n",
    "numeric_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если корреляция между признаками по модулю высокая, они будут \"мешаться\" друг другу при обучении линейной модели, потому что вносят похожую информацию. Из набора нескольких коррелирующих признаков следует оставлять один. Оставьте среди числовых признаков только те, которые слабо коррелируют между собой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо мультиколлинеарности следует смотреть на корреляцию признаков с целевой переменной. Посмотрите на корреляцию столбца `price_doc` со всеми остальными и оставьте среди них только те, которые оказывают достаточно сильное влияние:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Страшный, но, возможно, удобный способ вывести цветную корреляционную таблицу прямо в `pandas` (на семинаре по визуализации расскажем, как сделать проще, не бойтесь).\n",
    "\n",
    "Содержательная часть только тут `data.corr()`, в остальное можно не вникать, это для красивого отображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr().style.format(\"{:.2}\").background_gradient(cmap='coolwarm', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OHE aka One Hot Encoding\n",
    "Что сейчас мешает просто взять и запустить LinearRegression? Дело в том, что три колонки содержат не понятные компьютеру числа, а текстовые значения, а именно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[nominal_feature_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть простой способ закодировать данные. Например, рассмотрим колонку `ecology`. Она принимает только следующие значения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(data.ecology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть два варианта действий:\n",
    "- просто заменить каждое значение на число (4 - 'excellent', 3 - 'good' etc.)\n",
    "- рассмотреть каждое значение как отдельный признак и создать в таблице новые колонки с названиями этих значений\n",
    "\n",
    "Подумайте, почему $1$й способ хорошо подойдёт для колонки `ecology`, а $2$й -- для других двух столбцов.\n",
    "\n",
    "Создайте словарь, сопоставляющий числовые значения от $0$ до $4$ описанию экологии от `'no data'` до `'excellent'` соответственно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно заменить значения в колонке `ecology` на заданные нами выше с помощью метода `.replace`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ecology = data.ecology.replace(to_replace=ecology_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для добавления новых колонок-признаков воспользуемся методом `.get_dummies`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['sub_area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели\n",
    "Обучите модель линейной регрессии на полученных данных, посмотрите на полученное качество и коэффициенты. Для объективной оценки не забудьте разделить выборку на обучающую и контрольную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data[target_column].values\n",
    "X = data.drop(target_column, axis=1)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем данные на обучающую и тестовую часть.\n",
    "# YOUR CODE\n",
    "\n",
    "# Создание модели, которая будет подбирать веса для признаков.\n",
    "# YOUR CODE\n",
    "\n",
    "# Просим модель подобрать веса для признаков.\n",
    "# YOUR CODE\n",
    "\n",
    "# Предсказываем значения с помощью модели.\n",
    "# На трейне.\n",
    "# YOUR CODE\n",
    "# На тесте.\n",
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормализация признаков\n",
    "Казалось бы, чем больше коэффициент модели, тем сильнее признак влияет на предсказание.\n",
    "\n",
    "Но давайте посмотрим на разброс признаков: некоторые принимают значения порядка $10-100$, а некоторые --- около $0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[numeric_feature_columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И тогда понятно, почему у некоторых признаков коэффициент может оказаться сильно меньше, чем у других. Потому что модели приходится с помощью коэффициентов приводить значения к одной шкале.\n",
    "\n",
    "Хорошим тоном является нормализация всех признаков. Например, можно привести значения каждого столбца к шкале $[0..1]$ с помощью следующего преобразования:\n",
    "$$\n",
    "\\frac{x - min(x)}{max(x)}\n",
    "$$\n",
    "\n",
    "Сделать это можно как ручками, так и с помощью питона:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Создаём инструмент для нормализации признаков.\n",
    "min_max_scaler = MinMaxScaler()\n",
    "# Преобразуем признаки (на выходе будет np.ndarray).\n",
    "X_scaled = min_max_scaler.fit_transform(X)\n",
    "# Преобразуем np.ndarray обратно в pandas таблицу для удобства.\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "Снова обучите модель, уже на новых данных после нормализации (не забудьте разбить на train и test нормализованную таблицу `X_scaled`!). Сравните качество и коэффициенты с тем, что получалось раньше.\n",
    "\n",
    "Какой признак влияет на предсказание сильнее всего?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регрессия из библиотеки scipy\n",
    "Конечно, линейная регрессия реализована не в одной питонячьей библиотеке. Например, есть такая версия из библиотеки `scipy`. Её достаточно сложно заставить предсказывать значения на новых (тестовых) данных, зато она предоставляет много статистической информации о процессе обучения и полученных коэффициентах модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "ols_model = sm.OLS(Y, X_scaled, hasconst=False)\n",
    "ols_results = ols_model.fit()\n",
    "print(ols_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Значение в `P>|t|` позволяет оценить **не**важность признака для модели (если значение близко к нулю, признак вносит значительный вклад в предсказания).\n",
    "- `R-squared` (доля объяснённой дисперсии) позволяет оценить, насколько хорошо модель описывает данные (чем ближе к 1, тем лучше).\n",
    "- `Prob (F-statistic)` говорит нам, насколько модель хуже, чем если бы мы просто положили все веса равными нулю (т.е. чем ближе это значение к 0, тем лучше наша модель по сравнению с константой).\n",
    "\n",
    "Если не очень боитесь математическую статистику и теорвер, можете сходить за подробностями [сюда](http://efavdb.com/interpret-linear-regression/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
